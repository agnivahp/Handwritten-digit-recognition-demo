{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "0: accuracy:0.08 loss: 244.063\n",
      "0: ********* epoch 1 ********* test accuracy:0.0974 test loss: 239.663\n",
      "10: accuracy:0.44 loss: 198.913\n",
      "20: accuracy:0.7 loss: 85.2687\n",
      "30: accuracy:0.81 loss: 56.5886\n",
      "40: accuracy:0.82 loss: 67.4736\n",
      "50: accuracy:0.87 loss: 43.9609\n",
      "50: ********* epoch 1 ********* test accuracy:0.8807 test loss: 40.2101\n",
      "60: accuracy:0.93 loss: 34.1624\n",
      "70: accuracy:0.87 loss: 45.205\n",
      "80: accuracy:0.95 loss: 21.8698\n",
      "90: accuracy:0.96 loss: 22.9495\n",
      "100: accuracy:0.9 loss: 33.2908\n",
      "100: ********* epoch 1 ********* test accuracy:0.9226 test loss: 26.7828\n",
      "110: accuracy:0.97 loss: 16.5502\n",
      "120: accuracy:0.9 loss: 31.5613\n",
      "130: accuracy:0.84 loss: 46.2334\n",
      "140: accuracy:0.92 loss: 26.3536\n",
      "150: accuracy:0.96 loss: 12.7338\n",
      "150: ********* epoch 1 ********* test accuracy:0.9506 test loss: 15.7844\n",
      "160: accuracy:0.94 loss: 24.3534\n",
      "170: accuracy:0.94 loss: 21.3683\n",
      "180: accuracy:0.93 loss: 24.5509\n",
      "190: accuracy:0.97 loss: 12.7653\n",
      "200: accuracy:0.91 loss: 25.9548\n",
      "200: ********* epoch 1 ********* test accuracy:0.9559 test loss: 13.6051\n",
      "210: accuracy:0.96 loss: 24.3758\n",
      "220: accuracy:0.97 loss: 6.74967\n",
      "230: accuracy:0.92 loss: 20.2383\n",
      "240: accuracy:0.96 loss: 14.0146\n",
      "250: accuracy:0.97 loss: 7.77015\n",
      "250: ********* epoch 1 ********* test accuracy:0.9685 test loss: 10.4793\n",
      "260: accuracy:0.97 loss: 8.59045\n",
      "270: accuracy:0.98 loss: 7.45719\n",
      "280: accuracy:0.98 loss: 6.02216\n",
      "290: accuracy:0.96 loss: 10.7978\n",
      "300: accuracy:0.94 loss: 24.5772\n",
      "300: ********* epoch 1 ********* test accuracy:0.9672 test loss: 10.6686\n",
      "310: accuracy:0.97 loss: 9.48292\n",
      "320: accuracy:0.97 loss: 8.75013\n",
      "330: accuracy:0.97 loss: 9.62789\n",
      "340: accuracy:0.97 loss: 15.9776\n",
      "350: accuracy:0.97 loss: 8.41767\n",
      "350: ********* epoch 1 ********* test accuracy:0.9706 test loss: 9.08053\n",
      "360: accuracy:0.94 loss: 24.0155\n",
      "370: accuracy:0.96 loss: 18.161\n",
      "380: accuracy:0.98 loss: 9.46236\n",
      "390: accuracy:0.98 loss: 8.43922\n",
      "400: accuracy:0.95 loss: 10.9228\n",
      "400: ********* epoch 1 ********* test accuracy:0.9721 test loss: 8.58964\n",
      "410: accuracy:0.96 loss: 11.1324\n",
      "420: accuracy:0.95 loss: 14.2202\n",
      "430: accuracy:0.94 loss: 17.2033\n",
      "440: accuracy:0.95 loss: 11.833\n",
      "450: accuracy:0.97 loss: 11.6715\n",
      "450: ********* epoch 1 ********* test accuracy:0.9741 test loss: 8.24167\n",
      "460: accuracy:0.93 loss: 21.5892\n",
      "470: accuracy:0.96 loss: 13.2192\n",
      "480: accuracy:0.97 loss: 11.0912\n",
      "490: accuracy:0.91 loss: 21.0711\n",
      "500: accuracy:0.99 loss: 5.16443\n",
      "500: ********* epoch 1 ********* test accuracy:0.9779 test loss: 7.19404\n",
      "510: accuracy:0.99 loss: 3.18652\n",
      "520: accuracy:0.95 loss: 9.92575\n",
      "530: accuracy:0.96 loss: 8.67367\n",
      "540: accuracy:0.95 loss: 12.8543\n",
      "550: accuracy:0.98 loss: 4.92565\n",
      "550: ********* epoch 1 ********* test accuracy:0.9786 test loss: 6.5902\n",
      "560: accuracy:0.99 loss: 6.75025\n",
      "570: accuracy:0.97 loss: 7.11142\n",
      "580: accuracy:0.98 loss: 7.3614\n",
      "590: accuracy:1.0 loss: 0.192067\n",
      "600: accuracy:0.96 loss: 8.96973\n",
      "600: ********* epoch 2 ********* test accuracy:0.9787 test loss: 6.66187\n",
      "610: accuracy:0.99 loss: 4.712\n",
      "620: accuracy:0.96 loss: 12.3385\n",
      "630: accuracy:0.99 loss: 4.50305\n",
      "640: accuracy:0.97 loss: 16.8727\n",
      "650: accuracy:0.99 loss: 9.85563\n",
      "650: ********* epoch 2 ********* test accuracy:0.982 test loss: 5.77545\n",
      "660: accuracy:0.97 loss: 5.4029\n",
      "670: accuracy:1.0 loss: 2.0321\n",
      "680: accuracy:0.97 loss: 12.2904\n",
      "690: accuracy:0.98 loss: 8.2775\n",
      "700: accuracy:0.98 loss: 8.46834\n",
      "700: ********* epoch 2 ********* test accuracy:0.9789 test loss: 6.31928\n",
      "710: accuracy:0.99 loss: 3.62693\n",
      "720: accuracy:0.97 loss: 19.8389\n",
      "730: accuracy:0.98 loss: 7.85979\n",
      "740: accuracy:0.99 loss: 3.55451\n",
      "750: accuracy:0.97 loss: 6.25239\n",
      "750: ********* epoch 2 ********* test accuracy:0.9814 test loss: 5.6975\n",
      "760: accuracy:0.98 loss: 3.96132\n",
      "770: accuracy:0.96 loss: 6.17878\n",
      "780: accuracy:0.97 loss: 8.51996\n",
      "790: accuracy:0.98 loss: 5.2291\n",
      "800: accuracy:0.99 loss: 2.57847\n",
      "800: ********* epoch 2 ********* test accuracy:0.9815 test loss: 5.58656\n",
      "810: accuracy:0.99 loss: 2.98059\n",
      "820: accuracy:0.97 loss: 4.51134\n",
      "830: accuracy:0.98 loss: 13.9371\n",
      "840: accuracy:0.96 loss: 14.0464\n",
      "850: accuracy:1.0 loss: 0.406304\n",
      "850: ********* epoch 2 ********* test accuracy:0.9847 test loss: 5.19512\n",
      "860: accuracy:0.98 loss: 6.48025\n",
      "870: accuracy:0.98 loss: 5.8614\n",
      "880: accuracy:0.97 loss: 9.192\n",
      "890: accuracy:0.98 loss: 5.82457\n",
      "900: accuracy:0.97 loss: 10.7949\n",
      "900: ********* epoch 2 ********* test accuracy:0.9849 test loss: 5.01041\n",
      "910: accuracy:1.0 loss: 1.36575\n",
      "920: accuracy:0.99 loss: 6.67488\n",
      "930: accuracy:0.96 loss: 13.2502\n",
      "940: accuracy:0.98 loss: 5.25116\n",
      "950: accuracy:0.97 loss: 8.63814\n",
      "950: ********* epoch 2 ********* test accuracy:0.9842 test loss: 4.87955\n",
      "960: accuracy:0.99 loss: 3.2807\n",
      "970: accuracy:0.98 loss: 5.15037\n",
      "980: accuracy:0.97 loss: 11.7828\n",
      "990: accuracy:0.99 loss: 3.67511\n",
      "1000: accuracy:0.97 loss: 8.63588\n",
      "1000: ********* epoch 2 ********* test accuracy:0.9844 test loss: 4.76587\n",
      "1010: accuracy:0.95 loss: 10.7869\n",
      "1020: accuracy:1.0 loss: 2.46269\n",
      "1030: accuracy:0.98 loss: 10.6815\n",
      "1040: accuracy:0.95 loss: 16.3708\n",
      "1050: accuracy:0.98 loss: 9.5068\n",
      "1050: ********* epoch 2 ********* test accuracy:0.9824 test loss: 5.242\n",
      "1060: accuracy:0.98 loss: 7.29918\n",
      "1070: accuracy:0.97 loss: 14.6242\n",
      "1080: accuracy:1.0 loss: 2.15055\n",
      "1090: accuracy:0.97 loss: 8.9396\n",
      "1100: accuracy:0.98 loss: 4.47584\n",
      "1100: ********* epoch 2 ********* test accuracy:0.9836 test loss: 5.05339\n",
      "1110: accuracy:0.94 loss: 14.7195\n",
      "1120: accuracy:0.96 loss: 13.6316\n",
      "1130: accuracy:1.0 loss: 2.30128\n",
      "1140: accuracy:0.98 loss: 7.82102\n",
      "1150: accuracy:0.97 loss: 8.98747\n",
      "1150: ********* epoch 2 ********* test accuracy:0.9846 test loss: 4.58119\n",
      "1160: accuracy:0.98 loss: 13.2663\n",
      "1170: accuracy:0.99 loss: 8.12263\n",
      "1180: accuracy:0.97 loss: 13.4453\n",
      "1190: accuracy:0.97 loss: 5.10397\n",
      "1200: accuracy:0.99 loss: 3.32098\n",
      "1200: ********* epoch 3 ********* test accuracy:0.9867 test loss: 4.24783\n",
      "1210: accuracy:1.0 loss: 2.32824\n",
      "1220: accuracy:0.97 loss: 8.89841\n",
      "1230: accuracy:0.97 loss: 7.76211\n",
      "1240: accuracy:0.99 loss: 2.18884\n",
      "1250: accuracy:0.97 loss: 10.0549\n",
      "1250: ********* epoch 3 ********* test accuracy:0.9852 test loss: 4.42634\n",
      "1260: accuracy:0.97 loss: 8.84198\n",
      "1270: accuracy:0.99 loss: 5.0128\n",
      "1280: accuracy:0.95 loss: 10.0715\n",
      "1290: accuracy:0.99 loss: 2.82808\n",
      "1300: accuracy:0.96 loss: 14.5213\n",
      "1300: ********* epoch 3 ********* test accuracy:0.9864 test loss: 4.42081\n",
      "1310: accuracy:0.96 loss: 14.0918\n",
      "1320: accuracy:0.99 loss: 3.42885\n",
      "1330: accuracy:0.98 loss: 4.94429\n",
      "1340: accuracy:1.0 loss: 1.91068\n",
      "1350: accuracy:1.0 loss: 0.300957\n",
      "1350: ********* epoch 3 ********* test accuracy:0.9841 test loss: 4.51198\n",
      "1360: accuracy:1.0 loss: 2.45945\n",
      "1370: accuracy:0.99 loss: 2.41869\n",
      "1380: accuracy:0.99 loss: 3.83275\n",
      "1390: accuracy:0.96 loss: 9.54378\n",
      "1400: accuracy:0.99 loss: 1.99908\n",
      "1400: ********* epoch 3 ********* test accuracy:0.9882 test loss: 3.71062\n",
      "1410: accuracy:1.0 loss: 1.34377\n",
      "1420: accuracy:0.98 loss: 5.19465\n",
      "1430: accuracy:0.99 loss: 2.54724\n",
      "1440: accuracy:1.0 loss: 0.644858\n",
      "1450: accuracy:1.0 loss: 0.469889\n",
      "1450: ********* epoch 3 ********* test accuracy:0.9873 test loss: 4.11439\n",
      "1460: accuracy:0.99 loss: 1.98819\n",
      "1470: accuracy:0.99 loss: 3.05432\n",
      "1480: accuracy:0.99 loss: 4.50501\n",
      "1490: accuracy:0.98 loss: 5.80156\n",
      "1500: accuracy:0.98 loss: 5.47586\n",
      "1500: ********* epoch 3 ********* test accuracy:0.9862 test loss: 3.97985\n",
      "1510: accuracy:0.99 loss: 3.58207\n",
      "1520: accuracy:0.99 loss: 2.79363\n",
      "1530: accuracy:0.98 loss: 5.32585\n",
      "1540: accuracy:0.97 loss: 4.75409\n",
      "1550: accuracy:1.0 loss: 2.20418\n",
      "1550: ********* epoch 3 ********* test accuracy:0.9888 test loss: 3.69293\n",
      "1560: accuracy:0.97 loss: 11.4384\n",
      "1570: accuracy:1.0 loss: 1.67148\n",
      "1580: accuracy:0.99 loss: 2.53421\n",
      "1590: accuracy:0.99 loss: 2.1764\n",
      "1600: accuracy:0.97 loss: 6.40402\n",
      "1600: ********* epoch 3 ********* test accuracy:0.9866 test loss: 3.94532\n",
      "1610: accuracy:0.99 loss: 6.62057\n",
      "1620: accuracy:0.98 loss: 2.2797\n",
      "1630: accuracy:0.95 loss: 10.211\n",
      "1640: accuracy:0.99 loss: 2.77823\n",
      "1650: accuracy:1.0 loss: 1.17713\n",
      "1650: ********* epoch 3 ********* test accuracy:0.9878 test loss: 3.60553\n",
      "1660: accuracy:0.98 loss: 8.06674\n",
      "1670: accuracy:1.0 loss: 0.844954\n",
      "1680: accuracy:1.0 loss: 2.75594\n",
      "1690: accuracy:0.99 loss: 3.5882\n",
      "1700: accuracy:0.99 loss: 4.34517\n",
      "1700: ********* epoch 3 ********* test accuracy:0.9876 test loss: 3.61621\n",
      "1710: accuracy:0.98 loss: 5.18989\n",
      "1720: accuracy:0.98 loss: 12.8896\n",
      "1730: accuracy:0.98 loss: 3.46578\n",
      "1740: accuracy:1.0 loss: 0.7334\n",
      "1750: accuracy:1.0 loss: 0.292072\n",
      "1750: ********* epoch 3 ********* test accuracy:0.9886 test loss: 3.51483\n",
      "1760: accuracy:0.98 loss: 4.5442\n",
      "1770: accuracy:0.98 loss: 8.27135\n",
      "1780: accuracy:0.99 loss: 1.45933\n",
      "1790: accuracy:0.99 loss: 1.93591\n",
      "1800: accuracy:0.98 loss: 5.50756\n",
      "1800: ********* epoch 4 ********* test accuracy:0.988 test loss: 3.93685\n",
      "1810: accuracy:0.98 loss: 3.53872\n",
      "1820: accuracy:1.0 loss: 0.855064\n",
      "1830: accuracy:0.99 loss: 2.94053\n",
      "1840: accuracy:1.0 loss: 0.358286\n",
      "1850: accuracy:1.0 loss: 0.223206\n",
      "1850: ********* epoch 4 ********* test accuracy:0.987 test loss: 4.07827\n",
      "1860: accuracy:1.0 loss: 0.715107\n",
      "1870: accuracy:1.0 loss: 0.466102\n",
      "1880: accuracy:1.0 loss: 0.918761\n",
      "1890: accuracy:0.99 loss: 2.49218\n",
      "1900: accuracy:0.99 loss: 2.79968\n",
      "1900: ********* epoch 4 ********* test accuracy:0.9862 test loss: 4.15436\n",
      "1910: accuracy:1.0 loss: 1.32728\n",
      "1920: accuracy:1.0 loss: 0.491162\n",
      "1930: accuracy:1.0 loss: 0.853006\n",
      "1940: accuracy:0.99 loss: 2.8617\n",
      "1950: accuracy:0.98 loss: 6.27866\n",
      "1950: ********* epoch 4 ********* test accuracy:0.9872 test loss: 3.90007\n",
      "1960: accuracy:0.96 loss: 8.07358\n",
      "1970: accuracy:1.0 loss: 1.08817\n",
      "1980: accuracy:1.0 loss: 1.41958\n",
      "1990: accuracy:0.98 loss: 2.67218\n",
      "2000: accuracy:1.0 loss: 0.932525\n",
      "2000: ********* epoch 4 ********* test accuracy:0.9882 test loss: 3.53517\n",
      "2010: accuracy:0.98 loss: 7.02879\n",
      "2020: accuracy:1.0 loss: 1.29119\n",
      "2030: accuracy:0.97 loss: 11.5123\n",
      "2040: accuracy:1.0 loss: 1.1567\n",
      "2050: accuracy:0.99 loss: 3.07989\n",
      "2050: ********* epoch 4 ********* test accuracy:0.9889 test loss: 3.50696\n",
      "2060: accuracy:0.99 loss: 2.30805\n",
      "2070: accuracy:0.98 loss: 5.99058\n",
      "2080: accuracy:0.99 loss: 4.13768\n",
      "2090: accuracy:0.98 loss: 3.10998\n",
      "2100: accuracy:1.0 loss: 0.495909\n",
      "2100: ********* epoch 4 ********* test accuracy:0.9887 test loss: 3.69124\n",
      "2110: accuracy:1.0 loss: 0.371818\n",
      "2120: accuracy:0.99 loss: 2.42721\n",
      "2130: accuracy:1.0 loss: 0.91091\n",
      "2140: accuracy:0.98 loss: 14.3653\n",
      "2150: accuracy:1.0 loss: 2.46248\n",
      "2150: ********* epoch 4 ********* test accuracy:0.9885 test loss: 3.73496\n",
      "2160: accuracy:0.99 loss: 1.62386\n",
      "2170: accuracy:1.0 loss: 0.472272\n",
      "2180: accuracy:1.0 loss: 1.69182\n",
      "2190: accuracy:1.0 loss: 2.41377\n",
      "2200: accuracy:0.98 loss: 4.69287\n",
      "2200: ********* epoch 4 ********* test accuracy:0.9884 test loss: 3.71728\n",
      "2210: accuracy:0.98 loss: 6.6584\n",
      "2220: accuracy:0.99 loss: 3.93493\n",
      "2230: accuracy:0.99 loss: 1.95119\n",
      "2240: accuracy:0.98 loss: 3.15426\n",
      "2250: accuracy:0.98 loss: 5.27631\n",
      "2250: ********* epoch 4 ********* test accuracy:0.9872 test loss: 3.89121\n",
      "2260: accuracy:1.0 loss: 1.04713\n",
      "2270: accuracy:0.99 loss: 2.09806\n",
      "2280: accuracy:0.97 loss: 12.4062\n",
      "2290: accuracy:1.0 loss: 0.602809\n",
      "2300: accuracy:0.99 loss: 1.53955\n",
      "2300: ********* epoch 4 ********* test accuracy:0.9886 test loss: 3.49274\n",
      "2310: accuracy:0.98 loss: 6.35837\n",
      "2320: accuracy:0.98 loss: 2.82796\n",
      "2330: accuracy:1.0 loss: 1.21364\n",
      "2340: accuracy:1.0 loss: 1.2688\n",
      "2350: accuracy:1.0 loss: 0.200453\n",
      "2350: ********* epoch 4 ********* test accuracy:0.9879 test loss: 3.89813\n",
      "2360: accuracy:0.98 loss: 3.7648\n",
      "2370: accuracy:0.98 loss: 2.77516\n",
      "2380: accuracy:0.99 loss: 3.07984\n",
      "2390: accuracy:0.97 loss: 7.40157\n",
      "2400: accuracy:1.0 loss: 0.384214\n",
      "2400: ********* epoch 5 ********* test accuracy:0.9892 test loss: 3.45083\n",
      "2410: accuracy:1.0 loss: 1.29567\n",
      "2420: accuracy:0.99 loss: 1.2249\n",
      "2430: accuracy:0.99 loss: 11.8175\n",
      "2440: accuracy:0.99 loss: 6.06026\n",
      "2450: accuracy:0.99 loss: 1.85227\n",
      "2450: ********* epoch 5 ********* test accuracy:0.9865 test loss: 3.95954\n",
      "2460: accuracy:0.99 loss: 2.71004\n",
      "2470: accuracy:0.99 loss: 3.17731\n",
      "2480: accuracy:1.0 loss: 1.57756\n",
      "2490: accuracy:0.98 loss: 4.42611\n",
      "2500: accuracy:0.99 loss: 1.23057\n",
      "2500: ********* epoch 5 ********* test accuracy:0.9885 test loss: 3.76223\n",
      "2510: accuracy:1.0 loss: 1.34284\n",
      "2520: accuracy:0.98 loss: 4.80764\n",
      "2530: accuracy:0.98 loss: 4.19583\n",
      "2540: accuracy:0.99 loss: 4.07369\n",
      "2550: accuracy:0.99 loss: 2.23751\n",
      "2550: ********* epoch 5 ********* test accuracy:0.9889 test loss: 3.53326\n",
      "2560: accuracy:1.0 loss: 1.30001\n",
      "2570: accuracy:1.0 loss: 0.72457\n",
      "2580: accuracy:1.0 loss: 0.186055\n",
      "2590: accuracy:0.99 loss: 3.10192\n",
      "2600: accuracy:0.98 loss: 5.891\n",
      "2600: ********* epoch 5 ********* test accuracy:0.9891 test loss: 3.81304\n",
      "2610: accuracy:0.98 loss: 2.8526\n",
      "2620: accuracy:0.98 loss: 6.99491\n",
      "2630: accuracy:1.0 loss: 0.734811\n",
      "2640: accuracy:0.98 loss: 2.23637\n",
      "2650: accuracy:0.98 loss: 3.5947\n",
      "2650: ********* epoch 5 ********* test accuracy:0.9899 test loss: 3.5754\n",
      "2660: accuracy:0.98 loss: 3.71243\n",
      "2670: accuracy:1.0 loss: 0.525831\n",
      "2680: accuracy:1.0 loss: 0.296802\n",
      "2690: accuracy:1.0 loss: 1.22968\n",
      "2700: accuracy:0.99 loss: 3.80648\n",
      "2700: ********* epoch 5 ********* test accuracy:0.9894 test loss: 3.38135\n",
      "2710: accuracy:1.0 loss: 1.22059\n",
      "2720: accuracy:0.99 loss: 8.67901\n",
      "2730: accuracy:0.99 loss: 1.49584\n",
      "2740: accuracy:1.0 loss: 1.61262\n",
      "2750: accuracy:0.97 loss: 6.33774\n",
      "2750: ********* epoch 5 ********* test accuracy:0.9902 test loss: 3.28938\n",
      "2760: accuracy:1.0 loss: 2.19691\n",
      "2770: accuracy:1.0 loss: 0.887489\n",
      "2780: accuracy:1.0 loss: 1.13896\n",
      "2790: accuracy:0.98 loss: 8.50929\n",
      "2800: accuracy:1.0 loss: 0.435277\n",
      "2800: ********* epoch 5 ********* test accuracy:0.9903 test loss: 3.13576\n",
      "2810: accuracy:1.0 loss: 0.451145\n",
      "2820: accuracy:0.99 loss: 3.83104\n",
      "2830: accuracy:1.0 loss: 0.626388\n",
      "2840: accuracy:0.99 loss: 2.94032\n",
      "2850: accuracy:1.0 loss: 0.645054\n",
      "2850: ********* epoch 5 ********* test accuracy:0.9891 test loss: 3.4011\n",
      "2860: accuracy:0.99 loss: 1.36624\n",
      "2870: accuracy:1.0 loss: 0.541432\n",
      "2880: accuracy:0.99 loss: 3.53762\n",
      "2890: accuracy:1.0 loss: 0.679664\n",
      "2900: accuracy:0.97 loss: 4.79026\n",
      "2900: ********* epoch 5 ********* test accuracy:0.9898 test loss: 3.23737\n",
      "2910: accuracy:0.98 loss: 3.08653\n",
      "2920: accuracy:0.99 loss: 2.66719\n",
      "2930: accuracy:1.0 loss: 1.17318\n",
      "2940: accuracy:0.98 loss: 5.80026\n",
      "2950: accuracy:1.0 loss: 0.93364\n",
      "2950: ********* epoch 5 ********* test accuracy:0.9886 test loss: 3.44077\n",
      "2960: accuracy:0.98 loss: 4.73462\n",
      "2970: accuracy:1.0 loss: 0.0688535\n",
      "2980: accuracy:1.0 loss: 1.51938\n",
      "2990: accuracy:1.0 loss: 2.01028\n",
      "3000: accuracy:1.0 loss: 0.899021\n",
      "3000: ********* epoch 6 ********* test accuracy:0.9902 test loss: 3.2633\n",
      "3010: accuracy:1.0 loss: 0.261711\n",
      "3020: accuracy:0.99 loss: 4.92752\n",
      "3030: accuracy:1.0 loss: 0.757397\n",
      "3040: accuracy:1.0 loss: 0.851255\n",
      "3050: accuracy:1.0 loss: 0.178071\n",
      "3050: ********* epoch 6 ********* test accuracy:0.9899 test loss: 3.28324\n",
      "3060: accuracy:0.98 loss: 4.07866\n",
      "3070: accuracy:0.98 loss: 5.07494\n",
      "3080: accuracy:1.0 loss: 0.171969\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8a1569e758af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatavis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_max_test_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8a1569e758af>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(i, update_test_data, update_train_data)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# the backpropagation training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkeep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#tensorflow demo Digit recognition\n",
    "#CNN\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflowvisu\n",
    "import math\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "# Download images and labels into mnist.test (10K images+labels) and mnist.train (60K images+labels)\n",
    "mnist = read_data_sets(\"data\", one_hot=True, reshape=False, validation_size=0)\n",
    "\n",
    "#placeholder for training set\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "\n",
    "#learning rate exponentially decaying\n",
    "learningRate = tf.placeholder(tf.float32)\n",
    "\n",
    "#variables to be determined\n",
    "# w = tf.Variable(tf.zeros([784,10]))\n",
    "# b = tf.Variable(tf.zeros([10]))\n",
    "W1 = tf.Variable(tf.truncated_normal([5, 5, 1, 4], stddev=0.1))\n",
    "B1 = tf.Variable(tf.ones([4])/10) # 2 is the number of output channels\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([5, 5, 4, 8], stddev=0.1))\n",
    "B2 = tf.Variable(tf.ones([8])/10) # 2 is the number of output channels\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([4, 4, 8, 12], stddev=0.1))\n",
    "B3 = tf.Variable(tf.ones([12])/10) # 2 is the number of output channels\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([7*7*12, 200], stddev=0.1))\n",
    "B4 = tf.Variable(tf.ones([200])/10) # 2 is the number of output channels\n",
    "\n",
    "W5 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.ones([10])/10) # 2 is the number of output channels\n",
    "\n",
    "\n",
    "\n",
    "# Y = tf.nn.softmax(tf.matmul(tf.reshape(X,[-1, 784]), w) + b)\n",
    "#XX = tf.reshape(X, [-1, 28*28])\n",
    "\n",
    "#dropout to take care of overfitting\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "#model\n",
    "stride = 1  # output is still 28x28\n",
    "Y1cnv = tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME')\n",
    "Y1 = tf.nn.relu(Y1cnv + B1)\n",
    "#Y1d = tf.nn.dropout(Y1, pkeep)\n",
    "stride = 2\n",
    "Y2cnv = tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME')\n",
    "Y2 = tf.nn.relu(Y2cnv + B2)\n",
    "#Y2d = tf.nn.dropout(Y2, pkeep)\n",
    "stride = 2\n",
    "Y3cnv = tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME')\n",
    "Y3 = tf.nn.relu(Y3cnv + B3)\n",
    "#Y3d = tf.nn.dropout(Y3, pkeep)\n",
    "\n",
    "YY = tf.reshape(Y3, shape=[-1, 7*7*12])\n",
    "Y4 = tf.nn.relu(tf.matmul(YY,W4) + B4)\n",
    "Y4d = tf.nn.dropout(Y4, pkeep)\n",
    "\n",
    "Ylogits = tf.matmul(Y4d, W5) + B5\n",
    "Y = tf.nn.softmax(Ylogits)\n",
    "#Y5cnv = tf.nn.conv2d(Y4d, W5, strides=[1, stride, stride, 1], padding='SAME')\n",
    "#Y5 = tf.nn.relu(Y5cnv + B5)\n",
    "#Y5d = tf.nn.dropout(Y5, pkeep)\n",
    "\n",
    "\n",
    "\n",
    "#placeholder for correct labels\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#loss function that needs to be minimized\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "# % of correct answers found in batch\n",
    "is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learningRate)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "\n",
    "# matplotlib visualisation\n",
    "allweights = tf.concat([tf.reshape(W1, [-1]), tf.reshape(W2, [-1])], 0)\n",
    "allbiases  = tf.concat([tf.reshape(B1, [-1]), tf.reshape(B2, [-1])], 0)\n",
    "I = tensorflowvisu.tf_format_mnist_images(X, Y, Y_)  # assembles 10x10 images by default\n",
    "It = tensorflowvisu.tf_format_mnist_images(X, Y, Y_, 1000, lines=25)  # 1000 images on 25 lines\n",
    "datavis = tensorflowvisu.MnistDataVis()\n",
    "\n",
    "\n",
    "#training\n",
    "lrmin = 0.0001\n",
    "lrmax = 0.003\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "#Training the model, 100 images at a time\n",
    "def training_step(i, update_test_data, update_train_data):\n",
    "\n",
    "    # training on batches of 100 images with 100 labels\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
    "    lr = lrmin+(lrmax-lrmin)*math.exp(-i/2000)\n",
    "    # compute training values for visualisation\n",
    "    if update_train_data:\n",
    "        a, c, im, w, b = sess.run([accuracy, cross_entropy, I, allweights, allbiases], feed_dict={X: batch_X, Y_: batch_Y, learningRate: lr, pkeep: 0.75})\n",
    "        datavis.append_training_curves_data(i, a, c)\n",
    "        datavis.append_data_histograms(i, w, b)\n",
    "        datavis.update_image1(im)\n",
    "        print(str(i) + \": accuracy:\" + str(a) + \" loss: \" + str(c))\n",
    "\n",
    "    # compute test values for visualisation\n",
    "    if update_test_data:\n",
    "        a, c, im = sess.run([accuracy, cross_entropy, It], feed_dict={X: mnist.test.images, Y_: mnist.test.labels, pkeep: 1})\n",
    "        datavis.append_test_curves_data(i, a, c)\n",
    "        datavis.update_image2(im)\n",
    "        print(str(i) + \": ********* epoch \" + str(i*100//mnist.train.images.shape[0]+1) + \" ********* test accuracy:\" + str(a) + \" test loss: \" + str(c))\n",
    "\n",
    "    # the backpropagation training step\n",
    "    sess.run(train_step, feed_dict={X: batch_X, Y_: batch_Y, learningRate: lr, pkeep: 0.75})\n",
    "\n",
    "\n",
    "#to animate plots\n",
    "#datavis.animate(training_step, iterations=100+1, train_data_update_freq=10, test_data_update_freq=50, more_tests_at_start=True)\n",
    "\n",
    "for i in range(10000+1):\n",
    "    training_step(i, i % 50 == 0, i % 10 == 0)\n",
    "\n",
    "print(\"Test accuracy: \" + str(datavis.get_max_test_accuracy()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
